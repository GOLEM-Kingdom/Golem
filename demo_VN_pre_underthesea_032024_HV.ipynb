{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g9IV1reyxiw",
        "outputId": "09d58b39-f0b3-4850-f445-8544e6dc3acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/MyDrive/LDS0/Topic_2_3_2_1/demo'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUVJNzpvj7-n",
        "outputId": "a4ce09f8-ee06-41c9-bab2-82b6877bf477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/LDS0/Topic_2_3_2_1/demo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tiền xử lý dữ liệu tiếng Việt"
      ],
      "metadata": {
        "id": "VxorV5ADJfIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install underthesea\n",
        "!pip install demoji\n",
        "!pip install pyvi"
      ],
      "metadata": {
        "id": "4ZPNbAQry57x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG1CUO_Yyr6t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from underthesea import word_tokenize, pos_tag, sent_tokenize\n",
        "import regex\n",
        "import demoji\n",
        "from pyvi import ViPosTagger, ViTokenizer\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CofhEKVtyr6x"
      },
      "outputs": [],
      "source": [
        "# https://underthesea.readthedocs.io/en/v1.1.5/readme.html\n",
        "# https://github.com/undertheseanlp/underthesea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kh8pRQOXyr6y"
      },
      "outputs": [],
      "source": [
        "##LOAD EMOJICON\n",
        "file = open('files/emojicon.txt', 'r', encoding=\"utf8\")\n",
        "emoji_lst = file.read().split('\\n')\n",
        "emoji_dict = {}\n",
        "for line in emoji_lst:\n",
        "    key, value = line.split('\\t')\n",
        "    emoji_dict[key] = str(value)\n",
        "file.close()\n",
        "#################\n",
        "#LOAD TEENCODE\n",
        "file = open('files/teencode.txt', 'r', encoding=\"utf8\")\n",
        "teen_lst = file.read().split('\\n')\n",
        "teen_dict = {}\n",
        "for line in teen_lst:\n",
        "    key, value = line.split('\\t')\n",
        "    teen_dict[key] = str(value)\n",
        "file.close()\n",
        "###############\n",
        "#LOAD TRANSLATE ENGLISH -> VNMESE\n",
        "file = open('files/english-vnmese.txt', 'r', encoding=\"utf8\")\n",
        "english_lst = file.read().split('\\n')\n",
        "english_dict = {}\n",
        "for line in english_lst:\n",
        "    key, value = line.split('\\t')\n",
        "    english_dict[key] = str(value)\n",
        "file.close()\n",
        "################\n",
        "#LOAD wrong words\n",
        "file = open('files/wrong-word.txt', 'r', encoding=\"utf8\")\n",
        "wrong_lst = file.read().split('\\n')\n",
        "file.close()\n",
        "#################\n",
        "#LOAD STOPWORDS\n",
        "file = open('files/vietnamese-stopwords.txt', 'r', encoding=\"utf8\")\n",
        "stopwords_lst = file.read().split('\\n')\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P38CCWpyr6y"
      },
      "outputs": [],
      "source": [
        "def process_text(text, emoji_dict, teen_dict, wrong_lst):\n",
        "    document = text.lower()\n",
        "    document = document.replace(\"’\",'')\n",
        "    document = regex.sub(r'\\.+', \".\", document)\n",
        "    new_sentence =''\n",
        "    for sentence in sent_tokenize(document):\n",
        "        # if not(sentence.isascii()):\n",
        "        ###### CONVERT EMOJICON\n",
        "        sentence = ''.join(emoji_dict[word]+' ' if word in emoji_dict else word for word in list(sentence))\n",
        "        ###### CONVERT TEENCODE\n",
        "        sentence = ' '.join(teen_dict[word] if word in teen_dict else word for word in sentence.split())\n",
        "        ###### DEL Punctuation & Numbers\n",
        "        pattern = r'(?i)\\b[a-záàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ]+\\b'\n",
        "        sentence = ' '.join(regex.findall(pattern,sentence))\n",
        "        # ...\n",
        "        ###### DEL wrong words\n",
        "        sentence = ' '.join('' if word in wrong_lst else word for word in sentence.split())\n",
        "        new_sentence = new_sentence+ sentence + '. '\n",
        "    document = new_sentence\n",
        "    #print(document)\n",
        "    ###### DEL excess blank space\n",
        "    document = regex.sub(r'\\s+', ' ', document).strip()\n",
        "    #...\n",
        "    return document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wums9sysyr60"
      },
      "outputs": [],
      "source": [
        "# Chuẩn hóa unicode tiếng việt\n",
        "def loaddicchar():\n",
        "    uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n",
        "    unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
        "\n",
        "    dic = {}\n",
        "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
        "        '|')\n",
        "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
        "        '|')\n",
        "    for i in range(len(char1252)):\n",
        "        dic[char1252[i]] = charutf8[i]\n",
        "    return dic\n",
        "\n",
        "# Đưa toàn bộ dữ liệu qua hàm này để chuẩn hóa lại\n",
        "def covert_unicode(txt):\n",
        "    dicchar = loaddicchar()\n",
        "    return regex.sub(\n",
        "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
        "        lambda x: dicchar[x.group()], txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auHk1SStyr61"
      },
      "outputs": [],
      "source": [
        "def process_special_word(text):\n",
        "    # có thể có nhiều từ đặc biệt cần ráp lại với nhau\n",
        "    new_text = ''\n",
        "    text_lst = text.split()\n",
        "    i= 0\n",
        "    # không, chẳng, chả...\n",
        "    if 'không' in text_lst:\n",
        "        while i <= len(text_lst) - 1:\n",
        "            word = text_lst[i]\n",
        "            #print(word)\n",
        "            #print(i)\n",
        "            if  word == 'không':\n",
        "                next_idx = i+1\n",
        "                if next_idx <= len(text_lst) -1:\n",
        "                    word = word +'_'+ text_lst[next_idx]\n",
        "                i= next_idx + 1\n",
        "            else:\n",
        "                i = i+1\n",
        "            new_text = new_text + word + ' '\n",
        "    else:\n",
        "        new_text = text\n",
        "    return new_text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Hàm để chuẩn hóa các từ có ký tự lặp\n",
        "def normalize_repeated_characters(text):\n",
        "    # Thay thế mọi ký tự lặp liên tiếp bằng một ký tự đó\n",
        "    # Ví dụ: \"ngonnnn\" thành \"ngon\", \"thiệtttt\" thành \"thiệt\"\n",
        "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
        "\n",
        "# Áp dụng hàm chuẩn hóa cho văn bản\n",
        "# print(normalize_repeated_characters(example))"
      ],
      "metadata": {
        "id": "gq6q_AkInTO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFuQF1gMyr62"
      },
      "outputs": [],
      "source": [
        "def process_postag_thesea(text):\n",
        "    new_document = ''\n",
        "    for sentence in sent_tokenize(text):\n",
        "        sentence = sentence.replace('.','')\n",
        "        ###### POS tag\n",
        "        lst_word_type = ['N','Np','A','AB','V','VB','VY','R']\n",
        "        # lst_word_type = ['A','AB','V','VB','VY','R']\n",
        "        sentence = ' '.join( word[0] if word[1].upper() in lst_word_type else '' for word in pos_tag(process_special_word(word_tokenize(sentence, format=\"text\"))))\n",
        "        new_document = new_document + sentence + ' '\n",
        "    ###### DEL excess blank space\n",
        "    new_document = regex.sub(r'\\s+', ' ', new_document).strip()\n",
        "    return new_document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSX3s05Zyr62"
      },
      "outputs": [],
      "source": [
        "def remove_stopword(text, stopwords):\n",
        "    ###### REMOVE stop words\n",
        "    document = ' '.join('' if word in stopwords else word for word in text.split())\n",
        "    #print(document)\n",
        "    ###### DEL excess blank space\n",
        "    document = regex.sub(r'\\s+', ' ', document).strip()\n",
        "    return document"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tạo thêm các cột mới dựa trên việc đếm từ/icon positive và negative\n",
        "- Tạo danh sách các từ positive -> lưu vào file positive_VN.txt (mỗi từ trên 1 dòng)\n",
        "- Tạo danh sách các từ negative -> lưu vào file negative_VN.txt (mỗi từ trên 1 dòng)\n",
        "- Tạo danh sách các positve emojis -> lưu vào file positive_emoji.txt (mỗi icon trên 1 dòng)\n",
        "- Tạo danh sách các negative emojis -> lưu vào file negative_emoji.txt (mỗi icon trên 1 dòng)\n",
        "- Đọc vào các list tương ứng\n",
        "- Viết function để đọc 1 chuỗi -> đếm số lượng positive words/ emojis hoặc  negative words/ ememojis, danh sách từ kết quả\n",
        "- Tạo ra 2 cột mới cho dataframe: negative_count/ positive_count\n",
        "- ..."
      ],
      "metadata": {
        "id": "ojRtRJSx8CZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bổ sung thêm\n",
        "positive_words = [\n",
        "    \"thích\", \"tốt\", \"xuất sắc\", \"tuyệt vời\", \"tuyệt hảo\", \"đẹp\", \"ổn\", \"ngon\",\n",
        "    \"hài lòng\", \"ưng ý\", \"hoàn hảo\", \"chất lượng\", \"thú vị\", \"nhanh\",\n",
        "    \"tiện lợi\", \"dễ sử dụng\", \"hiệu quả\", \"ấn tượng\",\n",
        "    \"nổi bật\", \"tận hưởng\", \"tốn ít thời gian\", \"thân thiện\", \"hấp dẫn\",\n",
        "    \"gợi cảm\", \"tươi mới\", \"lạ mắt\", \"cao cấp\", \"độc đáo\",\n",
        "    \"hợp khẩu vị\", \"rất tốt\", \"rất thích\", \"tận tâm\", \"đáng tin cậy\", \"đẳng cấp\",\n",
        "    \"hấp dẫn\", \"an tâm\", \"không thể cưỡng lại\", \"thỏa mãn\", \"thúc đẩy\",\n",
        "    \"cảm động\", \"phục vụ tốt\", \"làm hài lòng\", \"gây ấn tượng\", \"nổi trội\",\n",
        "    \"sáng tạo\", \"quý báu\", \"phù hợp\", \"tận tâm\",\n",
        "    \"hiếm có\", \"cải thiện\", \"hoà nhã\", \"chăm chỉ\", \"cẩn thận\",\n",
        "    \"vui vẻ\", \"sáng sủa\", \"hào hứng\", \"đam mê\", \"vừa vặn\", \"đáng tiền\"\n",
        "]"
      ],
      "metadata": {
        "id": "fl9Jse0l9buR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(positive_words)"
      ],
      "metadata": {
        "id": "U1qEeyJv9tf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c8acb8-6f5e-4423-8dfe-587a8659790c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bổ sung thêm...\n",
        "negative_words = [\n",
        "    \"kém\", \"tệ\", \"đau\", \"xấu\", \"dở\", \"ức\",\n",
        "    \"buồn\", \"rối\", \"thô\", \"lâu\", \"chán\"\n",
        "    \"tối\", \"chán\", \"ít\", \"mờ\", \"mỏng\",\n",
        "    \"lỏng lẻo\", \"khó\", \"cùi\", \"yếu\",\n",
        "    \"kém chất lượng\", \"không thích\", \"không thú vị\", \"không ổn\",\n",
        "    \"không hợp\", \"không đáng tin cậy\", \"không chuyên nghiệp\",\n",
        "    \"không phản hồi\", \"không an toàn\", \"không phù hợp\", \"không thân thiện\", \"không linh hoạt\", \"không đáng giá\",\n",
        "    \"không ấn tượng\", \"không tốt\", \"chậm\", \"khó khăn\", \"phức tạp\",\n",
        "    \"khó hiểu\", \"khó chịu\", \"gây khó dễ\", \"rườm rà\", \"khó truy cập\",\n",
        "    \"thất bại\", \"tồi tệ\", \"khó xử\", \"không thể chấp nhận\", \"tồi tệ\",\"không rõ ràng\",\n",
        "    \"không chắc chắn\", \"rối rắm\", \"không tiện lợi\", \"không đáng tiền\", \"chưa đẹp\", \"không đẹp\"\n",
        "]"
      ],
      "metadata": {
        "id": "lQLgtqZv9Ye5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(negative_words)"
      ],
      "metadata": {
        "id": "Heg5npFz-ZvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9876988-a428-41f5-b088-4d14c3c6d152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_words(document, list_of_words):\n",
        "    document_lower = document.lower()\n",
        "    word_count = 0\n",
        "    word_list = []\n",
        "\n",
        "    for word in list_of_words:\n",
        "        if word in document_lower:\n",
        "            print(word)\n",
        "            word_count += document_lower.count(word)\n",
        "            word_list.append(word)\n",
        "\n",
        "    return word_count, word_list"
      ],
      "metadata": {
        "id": "Z4utzELqC-nH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count emojis positive and negative\n",
        "# bổ sung thêm...\n",
        "negative_emojis = [\n",
        "    \"😞\", \"😔\", \"🙁\", \"☹️\", \"😕\",\n",
        "    \"😢\", \"😭\", \"😖\", \"😣\", \"😩\",\n",
        "    \"😠\", \"😡\", \"🤬\", \"😤\", \"😰\",\n",
        "    \"😨\", \"😱\", \"😪\", \"😓\", \"🥺\",\n",
        "    \"😒\", \"🙄\", \"😑\", \"😬\", \"😶\",\n",
        "    \"🤯\", \"😳\", \"🤢\", \"🤮\", \"🤕\",\n",
        "    \"🥴\", \"🤔\", \"😷\", \"🙅‍♂️\", \"🙅‍♀️\",\n",
        "    \"🙆‍♂️\", \"🙆‍♀️\", \"🙇‍♂️\", \"🙇‍♀️\", \"🤦‍♂️\",\n",
        "    \"🤦‍♀️\", \"🤷‍♂️\", \"🤷‍♀️\", \"🤢\", \"🤧\",\n",
        "    \"🤨\", \"🤫\", \"👎\", \"👊\", \"✊\", \"🤛\", \"🤜\",\n",
        "    \"🤚\", \"🖕\"\n",
        "]"
      ],
      "metadata": {
        "id": "nBYIj19XFJkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(negative_emojis)"
      ],
      "metadata": {
        "id": "KmFhyhI9FkfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a112cd2b-d9cb-497e-e29d-00b4237b016a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_emojis = [\n",
        "    \"😄\", \"😃\", \"😀\", \"😁\", \"😆\",\n",
        "    \"😅\", \"🤣\", \"😂\", \"🙂\", \"🙃\",\n",
        "    \"😉\", \"😊\", \"😇\", \"🥰\", \"😍\",\n",
        "    \"🤩\", \"😘\", \"😗\", \"😚\", \"😙\",\n",
        "    \"😋\", \"😛\", \"😜\", \"🤪\", \"😝\",\n",
        "    \"🤗\", \"🤭\", \"🥳\", \"😌\", \"😎\",\n",
        "    \"🤓\", \"🧐\", \"👍\", \"🤝\", \"🙌\", \"👏\", \"👋\",\n",
        "    \"🤙\", \"✋\", \"🖐️\", \"👌\", \"🤞\",\n",
        "    \"✌️\", \"🤟\", \"👈\", \"👉\", \"👆\",\n",
        "    \"👇\", \"☝️\"\n",
        "]"
      ],
      "metadata": {
        "id": "CrCv5JJVGSi3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}